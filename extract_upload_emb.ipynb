{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nScript to generate embeddings for images (for catalog images) and store embeddings to Qdrant database.\\n@File    : image_embeddings_experiments.ipynb\\n@Author  : Nandini Bohra\\n@Contact : nbohra@ucsd.edu\\n\\n@References : https://www.youtube.com/watch?v=MlRkBvOCfTY\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script to generate embeddings for images (for catalog images) and store embeddings to Qdrant database.\n",
    "@File    : image_embeddings_experiments.ipynb\n",
    "@Author  : Nandini Bohra\n",
    "@Contact : nbohra@ucsd.edu\n",
    "\n",
    "@References : https://www.youtube.com/watch?v=MlRkBvOCfTY\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nandinibohra/Desktop/VSCodeFiles/ImageRecommendation_ProductMatching/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# for image resizing to b64\n",
    "from io import BytesIO\n",
    "import math\n",
    "import base64\n",
    "from PIL import Image\n",
    "\n",
    "# for importing in dinov2\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_url</th>\n",
       "      <th>type</th>\n",
       "      <th>material</th>\n",
       "      <th>color label</th>\n",
       "      <th>avg rgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/nandinibohra/Desktop/VSCodeFiles/ImageR...</td>\n",
       "      <td>samples</td>\n",
       "      <td>JUTE</td>\n",
       "      <td>CREAM</td>\n",
       "      <td>(np.int64(230), np.int64(223), np.int64(199))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/nandinibohra/Desktop/VSCodeFiles/ImageR...</td>\n",
       "      <td>samples</td>\n",
       "      <td>AURA</td>\n",
       "      <td>ROSE</td>\n",
       "      <td>(np.int64(223), np.int64(186), np.int64(158))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/Users/nandinibohra/Desktop/VSCodeFiles/ImageR...</td>\n",
       "      <td>samples</td>\n",
       "      <td>AURA</td>\n",
       "      <td>MINT</td>\n",
       "      <td>(np.int64(162), np.int64(191), np.int64(156))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/Users/nandinibohra/Desktop/VSCodeFiles/ImageR...</td>\n",
       "      <td>samples</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>OFFWHITE</td>\n",
       "      <td>(np.int64(241), np.int64(233), np.int64(218))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/Users/nandinibohra/Desktop/VSCodeFiles/ImageR...</td>\n",
       "      <td>samples</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>COFFEE</td>\n",
       "      <td>(np.int64(144), np.int64(123), np.int64(100))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          image_url     type material  \\\n",
       "0   0  /Users/nandinibohra/Desktop/VSCodeFiles/ImageR...  samples     JUTE   \n",
       "1   1  /Users/nandinibohra/Desktop/VSCodeFiles/ImageR...  samples     AURA   \n",
       "2   2  /Users/nandinibohra/Desktop/VSCodeFiles/ImageR...  samples     AURA   \n",
       "3   3  /Users/nandinibohra/Desktop/VSCodeFiles/ImageR...  samples  SURFACE   \n",
       "4   4  /Users/nandinibohra/Desktop/VSCodeFiles/ImageR...  samples  SURFACE   \n",
       "\n",
       "  color label                                        avg rgb  \n",
       "0       CREAM  (np.int64(230), np.int64(223), np.int64(199))  \n",
       "1        ROSE  (np.int64(223), np.int64(186), np.int64(158))  \n",
       "2        MINT  (np.int64(162), np.int64(191), np.int64(156))  \n",
       "3    OFFWHITE  (np.int64(241), np.int64(233), np.int64(218))  \n",
       "4      COFFEE  (np.int64(144), np.int64(123), np.int64(100))  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing in the payloads csv on all image information\n",
    "payloads = pd.read_csv(\"payloads.csv\")\n",
    "payloads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rgb(s):\n",
    "    if isinstance(s, str):\n",
    "        s = s.replace(\"int64\", \"\")\n",
    "        nums = list(map(int, re.findall(r\"\\d+\", s)))\n",
    "        if len(nums) == 3:\n",
    "            return nums  # [r, g, b]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "payloads[[\"r\", \"g\", \"b\"]] = payloads[\"avg rgb\"].apply(\n",
    "    lambda x: pd.Series(parse_rgb(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              int64\n",
       "image path     object\n",
       "type           object\n",
       "material       object\n",
       "color label    object\n",
       "r               int64\n",
       "g               int64\n",
       "b               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payloads = payloads.drop(columns=[\"avg rgb\"])\n",
    "payloads.rename(columns={\"image_url\": \"image path\"}, inplace=True)\n",
    "payloads.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image path</th>\n",
       "      <th>type</th>\n",
       "      <th>material</th>\n",
       "      <th>color label</th>\n",
       "      <th>r</th>\n",
       "      <th>g</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/nandinibohra/Desktop/VSCodeFiles/ImageR...</td>\n",
       "      <td>samples</td>\n",
       "      <td>JUTE</td>\n",
       "      <td>CREAM</td>\n",
       "      <td>230</td>\n",
       "      <td>223</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/nandinibohra/Desktop/VSCodeFiles/ImageR...</td>\n",
       "      <td>samples</td>\n",
       "      <td>AURA</td>\n",
       "      <td>ROSE</td>\n",
       "      <td>223</td>\n",
       "      <td>186</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/Users/nandinibohra/Desktop/VSCodeFiles/ImageR...</td>\n",
       "      <td>samples</td>\n",
       "      <td>AURA</td>\n",
       "      <td>MINT</td>\n",
       "      <td>162</td>\n",
       "      <td>191</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/Users/nandinibohra/Desktop/VSCodeFiles/ImageR...</td>\n",
       "      <td>samples</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>OFFWHITE</td>\n",
       "      <td>241</td>\n",
       "      <td>233</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/Users/nandinibohra/Desktop/VSCodeFiles/ImageR...</td>\n",
       "      <td>samples</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>COFFEE</td>\n",
       "      <td>144</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         image path     type material  \\\n",
       "0   0  /Users/nandinibohra/Desktop/VSCodeFiles/ImageR...  samples     JUTE   \n",
       "1   1  /Users/nandinibohra/Desktop/VSCodeFiles/ImageR...  samples     AURA   \n",
       "2   2  /Users/nandinibohra/Desktop/VSCodeFiles/ImageR...  samples     AURA   \n",
       "3   3  /Users/nandinibohra/Desktop/VSCodeFiles/ImageR...  samples  SURFACE   \n",
       "4   4  /Users/nandinibohra/Desktop/VSCodeFiles/ImageR...  samples  SURFACE   \n",
       "\n",
       "  color label    r    g    b  \n",
       "0       CREAM  230  223  199  \n",
       "1        ROSE  223  186  158  \n",
       "2        MINT  162  191  156  \n",
       "3    OFFWHITE  241  233  218  \n",
       "4      COFFEE  144  123  100  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payloads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Less for object classification and more for fine details, textures --> may be suitable for textile catalog\n",
    "# https://huggingface.co/facebook/dinov2-base\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def load_image_for_embedding(path, max_size=224):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    img.thumbnail((max_size, max_size))\n",
    "    return img\n",
    "\n",
    "def get_avg_emb(path):\n",
    "    image = load_image_for_embedding(path)\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    patches = outputs.last_hidden_state[:, 1:, :]\n",
    "    # print(f\"Patches shape: {patches.shape}\")\n",
    "    emb = torch.mean(patches, dim=1)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    emb = emb / emb.norm(dim=-1, keepdim=True)\n",
    "    # print(f\"Embedding shape (before squeeze): {emb.shape}\")\n",
    "    return emb.squeeze(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (50, 768)\n"
     ]
    }
   ],
   "source": [
    "image_paths = payloads[\"image path\"]\n",
    "embeddings = []\n",
    "for path in image_paths:\n",
    "    emb = get_avg_emb(path)\n",
    "    embeddings.append(emb)\n",
    "    \n",
    "embeddings = np.array(embeddings)\n",
    "print(f\"Embedding shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_len = embeddings.shape[1]\n",
    "embedding_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading embeddings to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Currently holding embeddings from DINOv2 + sample information in payloads\n",
    "# Loading Qdrant database access tokens from .env file\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p4/h22vp3dd135f5npjdy_vlh1c0000gn/T/ipykernel_86602/2650927517.py:5: UserWarning: Qdrant client version 1.13.2 is incompatible with server version 1.16.3. Major versions should match and minor version difference must not exceed 1. Set check_version=False to skip version check.\n",
      "  qclient = QdrantClient(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<qdrant_client.qdrant_client.QdrantClient at 0x28ff253a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing Qdrant client object\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qclient = QdrantClient(\n",
    "    url= os.getenv(\"QDRANT_DB_URL\"),\n",
    "    api_key= os.getenv(\"QDRANT_API_KEY\")\n",
    ")\n",
    "qclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p4/h22vp3dd135f5npjdy_vlh1c0000gn/T/ipykernel_86602/290729481.py:6: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  collection = qclient.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating collection in Qdrant database \n",
    "\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "collection_name = \"TextileProductRec\"\n",
    "collection = qclient.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=embedding_len,\n",
    "\n",
    "        # Previously tried DOT distance, but cosine distance is more suitable for image embeddings\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'image path': '/Users/nandinibohra/Desktop/VSCodeFiles/ImageRecommendation_ProductMatching/Product_Catalog/all_product_images/sample_images/sample_00.jpg',\n",
       "  'type': 'samples',\n",
       "  'material': 'JUTE',\n",
       "  'color label': 'CREAM',\n",
       "  'r': 230,\n",
       "  'g': 223,\n",
       "  'b': 199}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSONifying the payloads dataframe to format metadata for each point\n",
    "\n",
    "payload_dicts = payloads.to_dict(orient=\"records\")\n",
    "payload_dicts[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating records of payloads to load into Qdrant\n",
    "\n",
    "from qdrant_client import models\n",
    "\n",
    "records = [\n",
    "    models.Record(\n",
    "        id=idx,\n",
    "        payload=payload_dicts[idx],\n",
    "        vector=embeddings[idx]\n",
    "    )\n",
    "    for idx, _ in enumerate(payload_dicts)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p4/h22vp3dd135f5npjdy_vlh1c0000gn/T/ipykernel_86602/2914591607.py:3: DeprecationWarning: `upload_records` is deprecated, use `upload_points` instead\n",
      "  qclient.upload_records(\n"
     ]
    }
   ],
   "source": [
    "# Sending records to Qdrant database\n",
    "\n",
    "qclient.upload_records(\n",
    "    collection_name=collection_name,\n",
    "    records=records\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
